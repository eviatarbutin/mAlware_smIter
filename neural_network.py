import math

from torch.utils.data import Dataset
from torch.autograd import Variable
import torch.nn.functional as F
import torch.optim as optim
import torch.nn as nn
import torch
from create_dataset import create_dataset

from our_dataset import OurDataset 
from change_images_size import get_weights
from constants import *


class SimpleCNN(torch.nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        #Input channels = 3, output channels = 18
        # self.conv1 = torch.nn.Conv2d(1, 30, kernel_size = 3)
        # self.pool = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)
        
        self.conv = torch.nn.Conv2d(1, 60, kernel_size = 3)
        self.pool = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)
        
        self.droput = torch.nn.Dropout2d(0.25)   
        self.flatten = torch.nn.Flatten()


        #4608 input features, 64 output features (see sizing flow below)
        # self.fc1 = torch.nn.Linear(45 * 3 * 3, 128)
        self.fc1 = torch.nn.Linear(541500, 128)
        
        self.droput2 = torch.nn.Dropout2d(0.5)

        #64 input features, 10 output features for our 10 defined classes
        self.fc2 = torch.nn.Linear(128, 25)

    def forward(self, x):
        x = self.pool(F.relu(self.conv(x)))
        x = self.droput(x)
        # x = x.view(-1, 45 * 3 * 3)
        x = x.view(-1, 541500)
        x = self.fc1(x)
        x = self.droput2(x)
        x = self.flatten(x)
        x = self.fc2(x)
        return x

def split_dataset1(dataset):
    dataset_size = len(dataset)    
    # dataset, _ = torch.utils.data.random_split(dataset, [math.floor(dataset_size * 0.1), math.ceil(dataset_size * 0.9)])
    # dataset_size = len(dataset)    
    return torch.utils.data.random_split(dataset, [math.floor(dataset_size * 0.8), math.ceil(dataset_size * 0.2)])

def train_cnn(train_loader, cnn:SimpleCNN):
    print("training the cnn")
    # get the weights for each class to balance the unbalanced dataset
    class_weights = torch.FloatTensor(list(get_weights().values()))
    #This criterion computes the cross entropy loss between input and target
    criterion = nn.CrossEntropyLoss(class_weights)
    #Implements Adam algorithm
    optimizer = torch.optim.Adam(cnn.parameters(), lr=LEARNING_RATE)
    loses_epoch = []
    #number of teaching times
    for epoch in range(TRAINING_EPOCHS):
        loses = []
        #each image
        for batch in train_loader:
            images = batch["image"]
            classes = batch["tensor_class"]
            # teaching the dataset
            outputs = cnn(images)
            # calculating loss
            loss = criterion(outputs, classes)
            loses.append(loss)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        loses_epoch.append(sum(loses)/len(loses))
    print(loses_epoch)
    torch.save(cnn.state_dict(), "state_dict.pt")

def test_cnn(test_loader, cnn:SimpleCNN):
    print("testing the cnn")

    correct = 0
    total = 0
    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_loader:
            images = data["image"]
            labels = data["tensor_class"]


            # calculate outputs by running images through the network
            outputs = cnn(images)
            # the class with the highest energy is what we choose as prediction
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')
    
def test_file(data, cnn):
    images = data["image"]
    # calculate outputs by running images through the network
    outputs = cnn(images)
    # the class with the highest energy is what we choose as prediction
    _, predicted = torch.max(outputs.data, 1)    
    return predicted


def main():
    dataset = create_dataset()
    train_set, test_set = split_dataset1(dataset)

    train_loader = torch.utils.data.DataLoader(train_set, batch_size=1,
                                          shuffle=True, num_workers=2)
    test_loader = torch.utils.data.DataLoader(test_set, batch_size=1,
                                          shuffle=False, num_workers=2)
    cnn = SimpleCNN()
    # if torch.cuda.is_available():  
    #     dev = "cuda:0"
    # else:  
    #     dev = "cpu"  
    # device = torch.device(dev)  
    # cnn.to(device)

    train_cnn(train_loader, cnn)
    test_cnn(test_loader, cnn)



if __name__ == "__main__":
    main()
