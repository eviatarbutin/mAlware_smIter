import math

from torch.utils.data import Dataset
from torch.autograd import Variable
import torch.nn.functional as F
import torch.nn as nn
import torchvision
import pandas
import numpy
import torch
import cv2
import torch.optim as optim

from our_dataset import OurDataset 

class SimpleCNN(torch.nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        #Input channels = 3, output channels = 18
        # self.conv1 = torch.nn.Conv2d(1, 30, kernel_size = 3)
        # self.pool = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)
        
        self.conv = torch.nn.Conv2d(1, 60, kernel_size = 3)
        self.pool = torch.nn.MaxPool2d(kernel_size = 2, stride = 2)
        
        self.droput = torch.nn.Dropout2d(0.25)   
        self.flatten = torch.nn.Flatten()


        #4608 input features, 64 output features (see sizing flow below)
        self.fc1 = torch.nn.Linear(45 * 3 * 3, 128)
        
        self.droput2 = torch.nn.Dropout2d(0.5)   

        #64 input features, 10 output features for our 10 defined classes
        self.fc2 = torch.nn.Linear(64, 24)

    def forward(self, x):
        x = self.pool(F.relu(self.conv(x)))
        x = self.droput(x)
        x = x.view(-1, 45 * 3 * 3)
        x = self.fc1(x)
        x = self.droput2(x)
        x = self.flatten(x)
        x = self.fc2(x)
        return x

def split_dataset1(dataset):
    dataset_size = len(dataset)
    torch.utils.data.random_split(dataset, [math.floor(dataset_size * 0.8),math.ceil(dataset_size * 0.2)])

def main():
    dataset = OurDataset("default.json")

    train_set, test_set = split_dataset1(dataset)

    train_loader = torch.utils.data.DataLoader(train_set, batch_size=4,
                                          shuffle=True, num_workers=2)
    test_loader = torch.utils.data.DataLoader(test_set, batch_size=4,
                                          shuffle=False, num_workers=2)
    cnn =  SimpleCNN()
    i_love_epooch(train_loader, cnn)

def i_love_epooch(train_loader, cnn):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)

    running_loss = 0 
    printfreq = 1000
    for epoch in range(2):
        for i, data in enumerate(train_loader):
            inputs, labels = data
            optimizer.zero_grad()
            outputs = cnn(inputs)  # forward pass 
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            if i % printfreq == printfreq-1:  
                print(epoch, i+1, running_loss / printfreq)
                running_loss = 0 

if __name__ == "__main__":
    main()

